{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Machine learning in Python studies This repository includes different code to help me learn how to do machine learning with Python and jupyter notebook. It is based from different sources like: Python Machine learning - Sebastian Raschka's book Collective intelligence - Toby Segaran's book Stanford Machine learning training - Andrew Ng Intel ML 101 tutorial Environment To avoid impact to my laptop (Mac) python installation, I use docker image with python and all the needed library. The dockerfile is in this folder is used to build a development image. As some of the python codes are using matplotlib and graphics, it is possible to use the MAC display with docker and X11 display (see this blog ) for details. Install XQuartz with brew install xquartz . Then start Xquartz from the application or using: open -a Xquartz . A white terminal window will pop up. The first time Xquartz is started, open up the preferences menu and go to the security tab. Then select \u201callow connections from network clients\u201d to check it on. Build environment images: docker build -t jbcodeforce/python37 . Run python development shell When using graphic: start Xquartz from (applications/utilities), be sure the security settings allow connections from network clients. Then run the following command to open a two bi-directional streams between the docker container and the X window system of Xquartz. $ source ./setDisplay.sh $ socat TCP-LISTEN:6000,reuseaddr,fork UNIX-CLIENT: \\\" $DISPLAY \\\" which is what the socatStart.sh script does. Start a docker container with an active bash shell with the command: ./startPythonDocker.sh Then navigate to the python code from the current /home folder, and call python $ python deep-net-keras.py Code Classifiers Perceptron python TestPerceptron.py Adaline In ADALINE the weights are updated based on a linear activation function (the identity function) rather than a unit step function like in the perceptron. python TestAdaline.py Anomaly detection","title":"Introduction"},{"location":"#machine-learning-in-python-studies","text":"This repository includes different code to help me learn how to do machine learning with Python and jupyter notebook. It is based from different sources like: Python Machine learning - Sebastian Raschka's book Collective intelligence - Toby Segaran's book Stanford Machine learning training - Andrew Ng Intel ML 101 tutorial","title":"Machine learning in Python studies"},{"location":"#environment","text":"To avoid impact to my laptop (Mac) python installation, I use docker image with python and all the needed library. The dockerfile is in this folder is used to build a development image. As some of the python codes are using matplotlib and graphics, it is possible to use the MAC display with docker and X11 display (see this blog ) for details. Install XQuartz with brew install xquartz . Then start Xquartz from the application or using: open -a Xquartz . A white terminal window will pop up. The first time Xquartz is started, open up the preferences menu and go to the security tab. Then select \u201callow connections from network clients\u201d to check it on. Build environment images: docker build -t jbcodeforce/python37 .","title":"Environment"},{"location":"#run-python-development-shell","text":"When using graphic: start Xquartz from (applications/utilities), be sure the security settings allow connections from network clients. Then run the following command to open a two bi-directional streams between the docker container and the X window system of Xquartz. $ source ./setDisplay.sh $ socat TCP-LISTEN:6000,reuseaddr,fork UNIX-CLIENT: \\\" $DISPLAY \\\" which is what the socatStart.sh script does. Start a docker container with an active bash shell with the command: ./startPythonDocker.sh Then navigate to the python code from the current /home folder, and call python $ python deep-net-keras.py","title":"Run python development shell"},{"location":"#code","text":"","title":"Code"},{"location":"#classifiers","text":"","title":"Classifiers"},{"location":"#perceptron","text":"python TestPerceptron.py","title":"Perceptron"},{"location":"#adaline","text":"In ADALINE the weights are updated based on a linear activation function (the identity function) rather than a unit step function like in the perceptron. python TestAdaline.py","title":"Adaline"},{"location":"#anomaly-detection","text":"","title":"Anomaly detection"},{"location":"anomaly/","text":"Anomaly detection The goal for anomaly detection is, given a dataset {x(1), ... x(m)} and a Xtest dataset, the goal is to compute the probability that a X is anomalous: P(X test) < epsilon . It is used in user behavioral, like fraud detection, or manufactoring test, or computer monitoring in data center, but it can be also used by data scientist when doing data analysis to verify the data quality and to understand why there are some outliers. In anomaly detection, we fit a model P(X) to a set of negative (y=0) examples, without using any positive examples we may have collected of previously observed anomalies. There is a large number of normal examples, and a relatively small number of anomalous examples. P(X) is following a gaussian distribution. On the dataset we will fit a Gaussian distribution and then find values that have very low probability and hence can be considered anomalies. The red circles in the figure below are anomalies or outliers. Note Remember that the gaussian distribution is giving the probability of X using the mean and the variance sigma. The area under the bell curve is always equals to 1 Standard deviation A simple approach, on a unique numberical feature is to use the standard deviation: In statistical data distribution is approximately normal then about 68% of the data values lie within one standard deviation of the mean and about 95% are within two standard deviations, and about 99.7% lie within three standard deviations. See the code in [ml-python/anomaly-detection/StdDeviation.py]. When choosing features for an anomaly detection system, it is a good idea to look for features that take on unusually large or small values for (mainly the) anomalous examples. Box plot Box plots are a graphical depiction of numerical data through their quantiles. It is a very simple but effective way to visualize outliers. When to use it? use anomaly detection: When there is a very small number of positive example (y=1) Many different types of anomalies, it is hard for any algorithm to learn from positive examples what the anomalies look like Future anomalies may look nothing like any of the anomalous examples we've seen so far Fraud detection, monitoring machines in a data center, manufacturing use supervised learning When both positive and negative examples are large Enough positive examples for algorithm to get a sense of what positive examples are like Future positive examples likely to be similar to ones in training set Spam, weather prediction, cancer classification What feature to use for anomaly detection? historical data plot shows a bell curve like gaussian it is possible to transform a non-gaussian feature to a gaussian using square root, log,","title":"Anomaly detection"},{"location":"anomaly/#anomaly-detection","text":"The goal for anomaly detection is, given a dataset {x(1), ... x(m)} and a Xtest dataset, the goal is to compute the probability that a X is anomalous: P(X test) < epsilon . It is used in user behavioral, like fraud detection, or manufactoring test, or computer monitoring in data center, but it can be also used by data scientist when doing data analysis to verify the data quality and to understand why there are some outliers. In anomaly detection, we fit a model P(X) to a set of negative (y=0) examples, without using any positive examples we may have collected of previously observed anomalies. There is a large number of normal examples, and a relatively small number of anomalous examples. P(X) is following a gaussian distribution. On the dataset we will fit a Gaussian distribution and then find values that have very low probability and hence can be considered anomalies. The red circles in the figure below are anomalies or outliers. Note Remember that the gaussian distribution is giving the probability of X using the mean and the variance sigma. The area under the bell curve is always equals to 1","title":"Anomaly detection"},{"location":"anomaly/#standard-deviation","text":"A simple approach, on a unique numberical feature is to use the standard deviation: In statistical data distribution is approximately normal then about 68% of the data values lie within one standard deviation of the mean and about 95% are within two standard deviations, and about 99.7% lie within three standard deviations. See the code in [ml-python/anomaly-detection/StdDeviation.py]. When choosing features for an anomaly detection system, it is a good idea to look for features that take on unusually large or small values for (mainly the) anomalous examples.","title":"Standard deviation"},{"location":"anomaly/#box-plot","text":"Box plots are a graphical depiction of numerical data through their quantiles. It is a very simple but effective way to visualize outliers.","title":"Box plot"},{"location":"anomaly/#when-to-use-it","text":"use anomaly detection: When there is a very small number of positive example (y=1) Many different types of anomalies, it is hard for any algorithm to learn from positive examples what the anomalies look like Future anomalies may look nothing like any of the anomalous examples we've seen so far Fraud detection, monitoring machines in a data center, manufacturing use supervised learning When both positive and negative examples are large Enough positive examples for algorithm to get a sense of what positive examples are like Future positive examples likely to be similar to ones in training set Spam, weather prediction, cancer classification","title":"When to use it?"},{"location":"anomaly/#what-feature-to-use-for-anomaly-detection","text":"historical data plot shows a bell curve like gaussian it is possible to transform a non-gaussian feature to a gaussian using square root, log,","title":"What feature to use for anomaly detection?"},{"location":"compendium/","text":"Python Machine learning - Sebastian Raschka's book Collective intelligence - Toby Segaran's book Stanford Machine learning training - Andrew Ng Intel ML 101 tutorial","title":"Compendium"}]}